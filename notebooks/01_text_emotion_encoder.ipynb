{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1079e1",
   "metadata": {},
   "source": [
    "# Prompt2Song – Text Emotion Encoder\n",
    "\n",
    "Train an emotion-aware text encoder that powers both prompt understanding and lyric embeddings. This notebook ingests the six-class emotion dataset, fine-tunes a lightweight transformer, and exports reusable helpers for downstream stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd761f9",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- Inspect the prompt emotion dataset and build consistent label mappings\n",
    "- Fine-tune a DistilBERT-sized encoder on the six emotion classes\n",
    "- Export utility functions for prompt/lyric embeddings and persist artifacts for later notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cb7e5",
   "metadata": {},
   "source": [
    "> ⚙️ **Offline-friendly setup**  \n",
    "Ensure the base model weights (e.g. `distilbert-base-uncased`) are cached locally before running. Set `HF_HOME` or `TRANSFORMERS_CACHE` if you maintain an offline cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7321bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/4AL3py12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "try:\n",
    "    from transformers import (\n",
    "        AutoConfig,\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "        Trainer,\n",
    "        TrainingArguments,\n",
    "    )\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Install transformers before running this notebook.\") from exc\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Install scikit-learn before running this notebook.\") from exc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf65a1",
   "metadata": {},
   "source": [
    "Here we resolve project directories, ensure artifact folders exist, and define constants such as the dataset roots, model name, and random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0abca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/himanshu/Documents/Github/prompt2song\n",
      "Saving artifacts to: /Users/himanshu/Documents/Github/prompt2song/artifacts/text_encoder\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_DIR = Path.cwd().resolve()\n",
    "if (NOTEBOOK_DIR / \"datasets\").exists():\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR\n",
    "else:\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "DATASET_ROOT = PROJECT_ROOT / \"datasets\" / \"emotions_NLP\"\n",
    "ARTIFACT_ROOT = PROJECT_ROOT / \"artifacts\" / \"text_encoder\"\n",
    "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "SEED = 13\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Saving artifacts to: {ARTIFACT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf047e",
   "metadata": {},
   "source": [
    "Utility helper that seeds NumPy and PyTorch for reproducibility, then applies it using the configured seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6803fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 13) -> None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b097f",
   "metadata": {},
   "source": [
    "Loads the train/val/test splits from disk, cleans whitespace, filters empty rows, and prints a small preview plus dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8510392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    label\n",
      "0                            i didnt feel humiliated  sadness\n",
      "1  i can go from feeling so hopeless to so damned...  sadness\n",
      "2   im grabbing a minute to post i feel greedy wrong    anger\n",
      "3  i am ever feeling nostalgic about the fireplac...     love\n",
      "4                               i am feeling grouchy    anger\n",
      "{'train': 16000, 'val': 2000, 'test': 2000}\n"
     ]
    }
   ],
   "source": [
    "def load_split(split: str) -> pd.DataFrame:\n",
    "    path = DATASET_ROOT / f\"{split}.txt\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    df = pd.read_csv(path, sep=\";\", names=[\"text\", \"label\"], encoding=\"utf-8\")\n",
    "    df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "    df[\"label\"] = df[\"label\"].astype(str).str.strip()\n",
    "    df = df[df[\"text\"].str.len() > 0].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "train_df = load_split(\"train\")\n",
    "val_df = load_split(\"val\")\n",
    "test_df = load_split(\"test\")\n",
    "\n",
    "print(train_df.head())\n",
    "print({split: len(df) for split, df in {\"train\": train_df, \"val\": val_df, \"test\": test_df}.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325989d",
   "metadata": {},
   "source": [
    "Builds label↔id lookup tables, attaches numeric labels to each split, and reports label distribution for sanity checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ef21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'anger': 0, 'fear': 1, 'joy': 2, 'love': 3, 'sadness': 4, 'surprise': 5}\n",
      "Train distribution: label\n",
      "joy         5362\n",
      "sadness     4666\n",
      "anger       2159\n",
      "fear        1937\n",
      "love        1304\n",
      "surprise     572\n",
      "Name: count, dtype: int64\n",
      "Val distribution: label\n",
      "joy         704\n",
      "sadness     550\n",
      "anger       275\n",
      "fear        212\n",
      "love        178\n",
      "surprise     81\n",
      "Name: count, dtype: int64\n",
      "Test distribution: label\n",
      "joy         695\n",
      "sadness     581\n",
      "anger       275\n",
      "fear        224\n",
      "love        159\n",
      "surprise     66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(train_df[\"label\"].unique())\n",
    "labels_val = sorted(val_df[\"label\"].unique())\n",
    "labels_test = sorted(test_df[\"label\"].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "label2id_val = {label: idx for idx, label in enumerate(labels_val)}\n",
    "id2label_val = {idx: label for label, idx in label2id_val.items()}\n",
    "\n",
    "label2id_test = {label: idx for idx, label in enumerate(labels_test)}\n",
    "id2label_test = {idx: label for label, idx in label2id_test.items()}\n",
    "\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df[\"label_id\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "print(\"Label mapping:\", label2id)\n",
    "print(\"Train distribution:\", train_df[\"label\"].value_counts())\n",
    "print(\"Val distribution:\", val_df[\"label\"].value_counts())\n",
    "print(\"Test distribution:\", test_df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789a61d",
   "metadata": {},
   "source": [
    "Initializes the tokenizer and defines an EmotionDataset wrapper that tokenizes text samples on the fly before instantiating dataset objects for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c59402",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_length: int = 128):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        encoded = self.tokenizer(\n",
    "            row[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        item[\"labels\"] = torch.tensor(row[\"label_id\"], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = EmotionDataset(train_df, tokenizer)\n",
    "val_dataset = EmotionDataset(val_df, tokenizer)\n",
    "test_dataset = EmotionDataset(test_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a48bef",
   "metadata": {},
   "source": [
    "Creates a classification configuration for DistilBERT and loads the base model with the updated label metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9657b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06f0d4",
   "metadata": {},
   "source": [
    "Defines compute_metrics so the Trainer can report accuracy and macro/weighted F1 scores during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfeaf3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fdb68f",
   "metadata": {},
   "source": [
    "### Trainer configuration\n",
    "Adjust `per_device_train_batch_size`, `num_train_epochs`, or `learning_rate` for your hardware budget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85733489",
   "metadata": {},
   "source": [
    "Configures TrainingArguments (batch sizes, epochs, evaluation cadence, etc.) and instantiates the Hugging Face Trainer with datasets and metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c927ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=str(ARTIFACT_ROOT / \"checkpoints\"),\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41792f06",
   "metadata": {},
   "source": [
    "Optionally kicks off fine-tuning via trainer.train() and evaluates the pre-trained checkpoint to provide baseline metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a3982ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 19:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.185962</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.908392</td>\n",
       "      <td>0.935790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.205876</td>\n",
       "      <td>0.936500</td>\n",
       "      <td>0.908339</td>\n",
       "      <td>0.936045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.218917</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>0.915821</td>\n",
       "      <td>0.941343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/4AL3py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/anaconda3/envs/4AL3py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/anaconda3/envs/4AL3py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21891732513904572, 'eval_accuracy': 0.9415, 'eval_f1_macro': 0.9158210253830864, 'eval_f1_weighted': 0.9413434674766833, 'eval_runtime': 8.3612, 'eval_samples_per_second': 239.201, 'eval_steps_per_second': 7.535, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to launch full fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Example: evaluate initial (pre-trained) checkpoint before fine-tuning\n",
    "pretrain_metrics = trainer.evaluate()\n",
    "print(pretrain_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8d317",
   "metadata": {},
   "source": [
    "Runs final evaluation on the test split, then saves the fine-tuned model, tokenizer, and label mapping artifacts for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ba7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/4AL3py12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 0.25555408000946045, 'eval_accuracy': 0.9265, 'eval_f1_macro': 0.880847681956671, 'eval_f1_weighted': 0.925841848245525, 'eval_runtime': 8.6512, 'eval_samples_per_second': 231.183, 'eval_steps_per_second': 7.282, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# After calling trainer.train(), run evaluation and save artifacts\n",
    "eval_metrics = trainer.evaluate(test_dataset)\n",
    "print(\"Test metrics:\", eval_metrics)\n",
    "\n",
    "trainer.save_model(ARTIFACT_ROOT / \"hf_model\")\n",
    "tokenizer.save_pretrained(ARTIFACT_ROOT / \"hf_model\")\n",
    "\n",
    "with open(ARTIFACT_ROOT / \"label2id.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(label2id, fp, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02321df8",
   "metadata": {},
   "source": [
    "## Embedding helper\n",
    "Use the fine-tuned checkpoint to embed both prompts and lyrics via mean pooling of token embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa61da7",
   "metadata": {},
   "source": [
    "Implements a lightweight TextEmotionEncoder wrapper that loads the fine-tuned model and exposes a mean-pooled encode() helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d73f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmotionEncoder(torch.nn.Module):\n",
    "    def __init__(self, model_dir: Path, device: str | None = None):\n",
    "        super().__init__()\n",
    "        from transformers import AutoModel\n",
    "\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.base_model = AutoModel.from_pretrained(model_dir).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        embeddings = []\n",
    "        for start in range(0, len(texts), batch_size):\n",
    "            batch = texts[start:start+batch_size]\n",
    "            tokens = self.tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=256,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(self.device)\n",
    "            outputs = self.base_model(**tokens)\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            attention_mask = tokens.attention_mask.unsqueeze(-1)\n",
    "            summed = (token_embeddings * attention_mask).sum(dim=1)\n",
    "            counts = attention_mask.sum(dim=1)\n",
    "            mean_pooled = summed / counts\n",
    "            embeddings.append(mean_pooled.cpu().numpy())\n",
    "        return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f44614",
   "metadata": {},
   "source": [
    "Demonstrates encoding the training prompts with the helper and persists the resulting embeddings for downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6756feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (requires fine-tuned weights saved above)\n",
    "encoder = TextEmotionEncoder(ARTIFACT_ROOT / \"hf_model\")\n",
    "prompt_embeddings = encoder.encode(train_df[\"text\"].tolist())\n",
    "np.save(ARTIFACT_ROOT / \"train_prompt_embeddings.npy\", prompt_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850f64c",
   "metadata": {},
   "source": [
    "#### Quick demo\n",
    "Use a couple of sample prompts to verify the saved encoder produces fixed-size embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1, 768)\n",
      "Sample embeddings: 0.81536853\n"
     ]
    }
   ],
   "source": [
    "# Quick smoke test for the text encoder\n",
    "if (ARTIFACT_ROOT / 'hf_model').exists():\n",
    "    demo_encoder = TextEmotionEncoder(ARTIFACT_ROOT / 'hf_model')\n",
    "    sample_prompts = [\n",
    "        'I feel hopeful and excited about tomorrow',\n",
    "    ]\n",
    "    demo_embeddings = demo_encoder.encode(sample_prompts)\n",
    "    print('Embeddings shape:', demo_embeddings.shape)\n",
    "    print('Sample embeddings:', demo_embeddings[0][0])\n",
    "else:\n",
    "    print('⚠️ Fine-tuned weights not found; run trainer.train() and save artifacts first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec26490",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "- Run `trainer.train()` and persist the fine-tuned checkpoint once satisfied with metrics.\n",
    "- Use `TextEmotionEncoder` to embed the prompt dataset (`train`, `val`, `test`) for analysis or curricula.\n",
    "- Proceed to the audio encoder and multimodal fusion notebook after exporting `artifacts/text_encoder/hf_model`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4AL3py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
